# -*- coding: utf-8 -*-
"""project_final_draft for binary classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UY6rKQUxZ-YVP_x8QpmtJ3t53Kxj-o7B

> HCV Project: Final Draft
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np 
import pandas as pd
import matplotlib.pyplot as plt 
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn import tree
from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score
from sklearn.metrics import confusion_matrix as cm

from sklearn.model_selection import cross_val_score


# %matplotlib inline

from yellowbrick.classifier import ClassificationReport,ConfusionMatrix,ROCAUC,ClassPredictionError,ClassBalance 
from yellowbrick.model_selection import ValidationCurve,CVScores
from sklearn.neighbors import KNeighborsClassifier

import pydotplus 

from statistics import mean
from sklearn.model_selection import KFold

from IPython.display import Image
from yellowbrick.classifier import ClassificationReport,ConfusionMatrix

from sklearn.neighbors import KNeighborsClassifier # wtf 

from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score

from sklearn.decomposition import PCA

#import tensorflow as tf



# read data 
df = pd.read_csv('hcvdat0.csv')

df.head()

df.info()

def visualizer_fit_score_show(visualizer,X_train,y_train,X_test,y_test):
  visualizer.fit(X_train, y_train)  
  visualizer.score(X_test, y_test)
  visualizer.poof()

size = (800,500)
def visualize_all(classifier,X_train,y_train,X_test,y_test,y):

    ClassBalance(size=size).fit(y.values.ravel()).poof()
    ClassBalance(size=size,title='Training : Class Balances for '+str(len(y_train))+" instances").fit(y_train.values.ravel()).poof()
    ClassBalance(size=size,title='Testing : Class Balances for '+str(len(y_test))+" instances").fit(y_test.values.ravel()).poof()
    visualizer_fit_score_show(ConfusionMatrix(classifier,size=size),X_train,y_train,X_test,y_test)
    visualizer_fit_score_show(ClassificationReport(classifier,size=size),X_train,y_train,X_test,y_test)
    visualizer_fit_score_show(ClassPredictionError(classifier,size=size),X_train,y_train.values.ravel(),X_test,y_test.values.ravel())

"""### We wil detect and work on null values """

# check for na in entire df 
df.isnull().values.any()

# check for no of na entry in total column 
df.isnull().sum()

# ALB  1 
# ALP  18 DONE 
# ALT  1 
# CHOL 10 DONE
# PROT 1

# check no of null entry in ALP column 
df['ALP'].isnull().sum()

"""### What I want to do: 
### 1. Find the mean in attribute column for a given target label 
### 2. Replace the mean in the columns of that attribute column corresponding to a given target value 
"""

alp = df['ALP']
alp

# find the mean of ALP 
alp.mean(skipna=True)

target= df['Category']
#alp.join( target)

#pd.merge(alp, target) # no common columns to merge on

alp = pd.concat( [alp, target] , axis=1) # concatenated successfully 
alp.head()

# now, ALP and its target label are

y = df['Category']

# see unique values in target column 

df['Category'].unique()

alp.isnull().sum()

alp0 = alp[ alp['Category'] == '0=Blood Donor'] # Sanuj recommended this step on Assignment 1 
alp0.head() # Target: 0 Blood Donor

alp0.mean()

# check if any null value in alp0 
alp0.isnull().sum() # no null

alp0s = alp[ alp['Category'] == '0s=suspect Blood Donor'] # Sanuj recommended this step on Assignment 1 
alp0s.isnull().sum() # no null
alp0s

alp0s.mean()

alp1 = alp[ alp['Category'] == '1=Hepatitis'] # Sanuj recommended this step on Assignment 1 
alp1.isnull().sum() # 3 null in 18 instances 
#alp1 # to see null values

# we fill null values with the mean of the column 
#alp1.fillna(alp1['ALP'].mean(skipna=True), inplace = True)

alp1['ALP'].mean(skipna=True) # 42.11

#alp1['ALP'] = alp1['ALP'].fillna(mu)

#df.loc[np.isnan(df["Age"]), 'Age'] = rand1
#alp1.loc[np.isnan(df["ALP"]), 'ALP'] = mu


# fillna is throwing error 

alp1_ = alp1.fillna(alp1['ALP'].mean(skipna=True)) # throwing error when we add inplace=True
alp1_.head()

# do the steps above for ALP 2 


# 2=Fibrosis

alp2 = alp[ alp['Category'] == '2=Fibrosis'] # Sanuj recommended this step on Assignment 1 
alp2.isnull().sum() #  9 null in 21 instances 

alp2.shape

alp2_ = alp2.fillna(alp2['ALP'].mean(skipna=True)) # throwing error when we add inplace=True
alp2_.isnull().sum()

#3=Cirrhosis

alp3 = alp[ alp['Category'] == '3=Cirrhosis'] # Sanuj recommended this step on Assignment 1 
alp3.isnull().sum() #  6 null in 30 instances 

#alp3.shape

alp3_ = alp3.fillna(alp3['ALP'].mean(skipna=True)) # throwing error when we add inplace=True
alp3_.isnull().sum()

"""### concat alp0, alp0s, alp1_, alp2_, alp3_ onto a single df of 2 columns (Category, ALP) """

alp0
alp0s
alp1_ 
alp2_ 
alp3_ 

frames = [alp0, alp0s, alp1_ , alp2_ ,alp3_ ]
new_alp = pd.concat(frames)

new_alp.shape

new_alp.isnull().sum()

"""### Work on CHOL column """

df['CHOL'].isnull().sum() # there are 10 null values in CHOL column

df['CHOL'].min()

df['CHOL'].max()

df['CHOL'].median()

df['CHOL'].mean()

"""### FINDING: We see that the median and mean for CHOL is very close"""

chol = df['CHOL']


chol = pd.concat( [chol, target] , axis=1) # concatenated successfully 
chol.head()

"""### For each target label, find the mean of CHOL """

chol0 = chol[ chol['Category'] == '0=Blood Donor'] # Sanuj recommended this step on Assignment 1 
chol0.isnull().sum() #  7 null in 533 instances 

chol0.shape

print('chol0 min', chol0['CHOL'].min())
print('chol0 max', chol0['CHOL'].max())
print('chol0 mean: ', chol0['CHOL'].mean())
print('chol0 median: ', chol0['CHOL'].median())

# df[df['A'].isnull()].index.tolist()
chol0[chol0['CHOL'].isnull()].index.tolist()

# fill null values with mean 
chol0['CHOL']
chol0_ = chol0.fillna(chol0['CHOL'].mean(skipna=True)) # throwing error when we add inplace=True

chol0_.isnull().sum() # no null

chol['Category'].unique() # unique values in Category column

chol0s = chol[ chol['Category'] == '0s=suspect Blood Donor'] # Sanuj recommended this step on Assignment 1 
chol0s.isnull().sum() #  0 null in 7 instances 

chol0s.shape

chol1 = chol[ chol['Category'] == '1=Hepatitis'] # Sanuj recommended this step on Assignment 1 
chol1.isnull().sum() #  0 null in 24 instances 

#chol1.shape

# '2=Fibrosis'

chol2 = chol[ chol['Category'] == '2=Fibrosis'] # Sanuj recommended this step on Assignment 1 
chol2.isnull().sum() #  1 null in 21 instances 

#chol2.shape

chol2_ = chol2.fillna(chol2['CHOL'].mean(skipna=True)) # throwing error when we add inplace=True
chol2_.isnull().sum()

# '3=Cirrhosis'

chol3 = chol[ chol['Category'] == '3=Cirrhosis'] # Sanuj recommended this step on Assignment 1 
chol3.isnull().sum() #  2 null in 30 instances 

chol3.shape

chol3_ = chol3.fillna(chol3['CHOL'].mean(skipna=True)) # throwing error when we add inplace=True
chol3_.isnull().sum()

# CHID: merge chol0, chol0s, chol1 , chol2, chol3 onto a single df 

chol0_
chol0s
chol1 
chol2_ 
chol3_ 

chol_frames = [chol0_, chol0s, chol1 , chol2_ ,chol3_ ]
new_alp1 = pd.concat(chol_frames)

new_alp1.shape

new_alp1.isnull().sum()

new_alp1.head(5)

# alt - 1 null instance 
# prot - 1 null instance 

# alb - 1 null instance 

#print(df['ALB'].isnull().sum())

# df[df['A'].isnull()].index.tolist() --> get index

df[ df['ALB'].isnull() ].index.tolist() # at 603, there is null value 
print(df.loc[603, :]) # we see target = 3

# get mean of alb at 3=Cirrhosis

alb = df['ALB']

alb = pd.concat( [ alb, target ], axis=1) #df['ALB', 'Category']
alb3 = alb[ alb['Category'] == '3=Cirrhosis']

print('ALB 3 mean ', alb3['ALB'].mean() ) 
print('ALB 3 median ', alb3['ALB'].median() )
print('ALB 3 max ', alb3['ALB'].max() )
print('ALB 3 min ', alb3['ALB'].min() )

alb3_mean = alb3['ALB'].mean();

# CHID: fill with mean at that specific index

# CHID: Please add the mean ALB3 value at index 603(row) column ALB
df['ALB'].fillna(value= alb3_mean, inplace=True)

df.isnull().sum()

# ALT 

df[ df['ALT'].isnull() ].index.tolist() # at 540, there is null value 
print(df.loc[540, :]) # we see target = 1

# get mean of alt at 1=Hepatitis

alt = df['ALT']

alt = pd.concat( [ alt, target ], axis=1) #df['ALT', 'Category']
alt1 = alt[ alt['Category'] == '1=Hepatitis']
alt1_mean = alt1['ALT'].mean();

print('ALT 1 mean ', alt1['ALT'].mean() ) 
print('ALT 1 median ', alt1['ALT'].median() )
print('ALT 1 max ', alt1['ALT'].max() )
print('ALT 1 min ', alt1['ALT'].min() )

# CHID: fill with mean at that specific index
df['ALT'].fillna(value= alt1_mean, inplace=True)
df.isnull().sum()

df[ df['PROT'].isnull() ].index.tolist() # at 590, there is null value 
print(df.loc[590, :]) # we see target = 3

# get mean of PROT at 3=Cirrhosis

prot = df['PROT']

prot = pd.concat( [ prot, target ], axis=1) #df['ALT', 'Category']
prot3 = prot[ prot['Category'] == '1=Hepatitis']



prot3.head()

print('PROT 3 mean ', prot3['PROT'].mean() ) 
print('PROT 3 median ', prot3['PROT'].median() )
print('PROT 3 max ', prot3['PROT'].max() )
print('PROT 3 min ', prot3['PROT'].min() )

# CHID: fill with mean at that specific index
prot3_mean = prot3['PROT'].mean();
df['PROT'].fillna(value= prot3_mean, inplace=True)
df.isnull().sum()

#Replace the columns of ALP and CHOL with the new generated dataframes.

df = df.assign(ALP= new_alp['ALP'], CHOL= new_alp1['CHOL']);
df.isnull().sum()

# count the number of unique entries 

df.groupby('Category').nunique()

#Storing the df for multi-class classification
df_multiclass = df.copy()

"""### At this point, we convert 0/0s to 0 and 1/2/3 to 1

#### Notice that, 
#### 0 -> 533+7 = 540 instances, and
#### 1/2/3 -> 24+21+30 = 75 instances
"""

df_test = df.loc[(df.Category == '0=Blood Donor'), 'Category'] = 'No-Hepatitis'
df.groupby('Category').nunique()

df_test = df.loc[(df.Category == '0s=suspect Blood Donor'), 'Category'] = 'No-Hepatitis'
df.groupby('Category').nunique()

df.loc[(df.Category == '1=Hepatitis'), 'Category'] = 'Hepatitis'
df.loc[(df.Category == '2=Fibrosis'), 'Category'] = 'Hepatitis'


# df.groupby('Category').nunique()

df.loc[(df.Category == '3=Cirrhosis'), 'Category'] = 'Hepatitis'
df.groupby('Category').nunique()

# SR: We need to work on the gender column. Convert M and F to 1 and 0 
from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
category = le.fit_transform( df['Category'] ) 



# df.loc[(df.Category == 'Hepatitis'), 'Category'] = 1
# df.loc[(df.Category == 'No-Hepatitis	'), 'Category'] = 0



#type(gender) # numpy array 

# replace 'Sex' column w/ values in gender array
print (category)
df['Category']= category

df.loc[(df.Sex == 'm'), 'Sex'] = 1
df.loc[(df.Sex == 'f'), 'Sex'] = 0

df.groupby('Category').nunique()

# Covariation and Correlation
print ('Covariance:', df.cov());   
print ('Correlation:', df.corr());

df.head(5)

df.tail() # we see there is NaN entry- we need to address this

df.head(10)

Y= pd.DataFrame(data= df['Category']);
X= df.drop(['Category'], axis=1);

X_colnames = X.columns;

# SR: oversample the data 

from imblearn.over_sampling import SMOTE


sm = SMOTE(random_state=42)
X_res, Y_res = sm.fit_resample(X, Y)
type(Y)

print (type(X_res))

X.shape # (615, 13) 51
X_res.shape # (1080, 13)

X_resDataframe = pd.DataFrame(data=X_res, columns=X_colnames);
Y_resDataframe =  pd.DataFrame(data=Y_res, columns=["Category"]);

Y_resDataframe.info()

X_resDataframe.info()

X_train, X_test, Y_train, Y_test = train_test_split(X_resDataframe,Y_resDataframe,train_size=0.8, test_size=0.2, random_state=1) 
Y_train.head(5)

"""Standardize df before oversampling: DONE




"""

# SR: standarize the dataset 
from sklearn.preprocessing import StandardScaler

sc = StandardScaler()

X_train_std = sc.fit_transform(X_train)
X_test_std = sc.transform(X_test)

"""SR: Apply PCA, algorithms, and performance metrics on standardized data. Repeat the steps on the oversampled data. """

unique, frequency = np.unique(Y_res,  
                              return_counts = True) 
# print unique values array 
print("Unique Values:",  
      unique) 
  
# print frequency array 
print("Frequency Values:", 
      frequency)

unique, frequency = np.unique(Y, return_counts = True) 
# print unique values array 
print("Unique Values:",  
      unique) 
  
# print frequency array 
print("Frequency Values:", 
      frequency)

Y_bc_resDataframe =  pd.DataFrame(data=Y_res, columns=["Category"]);
ClassBalance(size=size).fit(Y_bc_resDataframe.values.ravel()).poof()

ClassBalance(size=size,title='Training : Class Balances for '+str(len(Y_train))+" instances").fit(Y_train.values.ravel()).poof()
ClassBalance(size=size,title='Testing : Class Balances for '+str(len(Y_test))+" instances").fit(Y_test.values.ravel()).poof()

#Classification algorithms
#Algorithm - Decision tree

maxdepths = [10,15,20,25,30,35,40]

trainAcc = np.zeros(len(maxdepths))
testAcc = np.zeros(len(maxdepths))
trainPrecision = np.zeros(len(maxdepths));
testPrecision = np.zeros(len(maxdepths))
trainRecall = np.zeros(len(maxdepths))
testRecall = np.zeros(len(maxdepths))
trainF1= np.zeros(len(maxdepths))
testF1 =  np.zeros(len(maxdepths))

index = 0
for depth in maxdepths:
    clf = tree.DecisionTreeClassifier(max_depth=depth, criterion="gini")
    clf = clf.fit(X_train_std, Y_train)
    Y_predTrain = clf.predict(X_train_std)
    Y_predTest = clf.predict(X_test_std)
    trainAcc[index] = accuracy_score(Y_train, Y_predTrain)
    testAcc[index] = accuracy_score(Y_test, Y_predTest)
    trainPrecision[index] = precision_score(Y_train, Y_predTrain)
    testPrecision[index] = precision_score(Y_test, Y_predTest)
    trainRecall[index] = recall_score(Y_train, Y_predTrain)
    testRecall[index] = recall_score(Y_test, Y_predTest)
    trainF1[index] = f1_score(Y_train, Y_predTrain)
    testF1[index] = f1_score(Y_test, Y_predTest)
    index+=1;
        
plt.plot(maxdepths,trainAcc,'ro-',maxdepths,testAcc,'bv--')
plt.legend(['Training Accuracy','Test Accuracy'])
plt.xlabel('Max depth')
plt.ylabel('Accuracy')
plt.title("Decision Tree-Accuracy")
print ('Trainaccuracy',trainAcc);
print ('Testaccuracy', testAcc)

plt.plot(maxdepths,trainPrecision,'ro-',maxdepths,testPrecision,'bv--')
plt.legend(['Training Precision','Test Precision'])
plt.xlabel('Max depth')
plt.ylabel('Precision')
plt.title("Decision Tree-Precision")

plt.plot(maxdepths,trainRecall,'ro-',maxdepths,testRecall,'bv--')
plt.legend(['Training Recall','Test Recall'])
plt.xlabel('Max depth')
plt.ylabel('Recall')
plt.title("Decision Tree-Recall")

plt.plot(maxdepths,trainF1,'ro-',maxdepths,testF1,'bv--')
plt.legend(['Training F1 score','Test F1 score'])
plt.xlabel('Max depth')
plt.ylabel('F1 score')
plt.title("Decision Tree-f1 score")

"""k Nearest Neighbor implementation by SR  """

X_resDataframe.shape

Y_resDataframe.shape

# For computational convenience, I scale the X_resDataframe
# SR: standarize the dataset 
from sklearn.preprocessing import StandardScaler

sc = StandardScaler()

X_resDataframe_std = sc.fit_transform(X_resDataframe)

# kNN by Shahriar 

# We want to try kNN- a supervised algorithm- on the data set. 
# Before that, we want to find the best value for k which we can use on our dataset 


i_ = []
mu = []
for i in range(1, 101): 
    
    knn = KNeighborsClassifier(n_neighbors=i)
    #cross_val_score( X, y) # parameters: estimator, X, target label, n_splits 
    scores = cross_val_score(knn, X, y, cv=10, scoring='accuracy') 
    
    #print(scores)
    #print('Scores for i= ', i, ': ', scores.mean())
    i_.append( i ) # k value 
    mu.append( scores.mean() ) # accuracy

print()

# plot test and training accuracy onto one graph 

plt.plot(i_, mu, label='Accuracy vs K value')

plt.xlabel('K value')
plt.ylabel('Accuracy/%')

plt.legend(loc='upper right')
plt.grid(alpha=0.5)

plt.savefig('Best K Value: k_fold_cross_validation_acc_vs_kvalue.png') # We need this 

plt.show()

# Find the k value for maximum accuracy 
max(mu) # 98 %
max_ = []
# find the indices for max
for i in range( len(mu) ):
    if mu[i] == max(mu):
        max_.append(i+1)

best_k = max_[0]        
print('Optimum k value for the original dataset', max_ )

# kNN by Chid Crushev 

#Knn classfier-euclidean distance

numNeighbors = [1, 5, 10, 15, 20, 25]
trainAcc_euclidean = []
testAcc_euclidean = []
trainPrecision =[];
testPrecision = [];
trainRecall = [];
testRecall = [];
trainF1 = [];
testF1 = [];

for k in numNeighbors:
    clf = KNeighborsClassifier(n_neighbors=k, metric='euclidean')
    clf.fit(X_train_std, Y_train.values.ravel())
    Y_predTrain = clf.predict(X_train_std)
    Y_predTest = clf.predict(X_test_std)
    trainAcc_euclidean.append(accuracy_score(Y_train, Y_predTrain))
    testAcc_euclidean.append(accuracy_score(Y_test, Y_predTest))
    trainPrecision.append (precision_score(Y_train, Y_predTrain))
    testPrecision.append (precision_score(Y_test, Y_predTest))
    trainRecall.append (recall_score(Y_train, Y_predTrain))
    testRecall.append (recall_score(Y_test, Y_predTest))
    trainF1.append (f1_score(Y_train, Y_predTrain))
    testF1.append (f1_score(Y_test, Y_predTest))

plt.plot(numNeighbors, trainAcc_euclidean, 'ro-', numNeighbors, testAcc_euclidean,'bv--')
plt.legend(['Training Accuracy','Test Accuracy'])
plt.xlabel('Number of neighbors')
plt.ylabel('Accuracy')
plt.title("KNN-Accuracy-Euclidean for Hep B Binary Classification")

plt.savefig('knn Binary Classification: kNN with Eucledian Distance Metrics')

print (trainAcc_euclidean);
print (testAcc_euclidean)

plt.plot(numNeighbors, trainPrecision, 'ro-', numNeighbors, testPrecision,'bv--')
plt.legend(['Training Precision','Test Precision'])
plt.xlabel('Number of neighbors')
plt.ylabel('Precision')
plt.title("KNN-Precision-Euclidean")
print (trainPrecision);
print (testPrecision);

plt.plot(numNeighbors, trainRecall, 'ro-', numNeighbors, testRecall,'bv--')
plt.legend(['Training Recall','Test Recall'])
plt.xlabel('Number of neighbors')
plt.ylabel('Recall')
plt.title("KNN-Recall-Euclidean")
print (trainRecall)
print (testRecall)

plt.plot(numNeighbors, trainF1, 'ro-', numNeighbors, testF1,'bv--')
plt.legend(['Training F1 score','Test F1 score'])
plt.xlabel('Number of neighbors')
plt.ylabel('F1 score')
plt.title("KNN-F1score-Euclidean")
print (trainF1)
print (testF1)

#Algorithm - SVM-linear

from sklearn import linear_model
from sklearn.svm import SVC

C = [0.01, 0.1, 0.2, 0.5, 0.8, 1, 5, 10, 20, 50]
LRtrainAcc = []
LRtestAcc = []
SVMtrainAcc = []
SVMtestAcc = []


LRtrainPrecision =[];
LRtestPrecision = [];
LRtrainRecall = [];
LRtestRecall = [];
LRtrainF1 = [];
LRtestF1 = [];

SVMtrainPrecision =[];
SVMtestPrecision = [];
SVMtrainRecall = [];
SVMtestRecall = [];
SVMtrainF1 = [];
SVMtestF1 = [];




for param in C:
    clf = linear_model.LogisticRegression(C=param)
    clf.fit(X_train_std, Y_train.values.ravel())
    Y_predTrain = clf.predict(X_train_std)
    Y_predTest = clf.predict(X_test_std)
    LRtrainAcc.append(accuracy_score(Y_train, Y_predTrain))
    LRtestAcc.append(accuracy_score(Y_test, Y_predTest))
    LRtrainPrecision.append (precision_score(Y_train, Y_predTrain))
    LRtestPrecision.append (precision_score(Y_test, Y_predTest))
    LRtrainRecall.append (recall_score(Y_train, Y_predTrain))
    LRtestRecall.append (recall_score(Y_test, Y_predTest))
    LRtrainF1.append (f1_score(Y_train, Y_predTrain))
    LRtestF1.append (f1_score(Y_test, Y_predTest))

    clf = SVC(C=param,kernel='linear')
    clf.fit(X_train_std, Y_train.values.ravel())
    Y_predTrain = clf.predict(X_train_std)
    Y_predTest = clf.predict(X_test_std)
    SVMtrainAcc.append(accuracy_score(Y_train, Y_predTrain))
    SVMtestAcc.append(accuracy_score(Y_test, Y_predTest))
    SVMtrainPrecision.append (precision_score(Y_train, Y_predTrain))
    SVMtestPrecision.append (precision_score(Y_test, Y_predTest))
    SVMtrainRecall.append (recall_score(Y_train, Y_predTrain))
    SVMtestRecall.append (recall_score(Y_test, Y_predTest))
    SVMtrainF1.append (f1_score(Y_train, Y_predTrain))
    SVMtestF1.append (f1_score(Y_test, Y_predTest))

#Logistic regression -metrics

# overfitting - see diagram 

plt.plot(C, LRtrainAcc, 'ro-', C, LRtestAcc,'bv--')
plt.legend(['Training Accuracy','Test Accuracy'])
plt.xlabel('C')
plt.xscale('Log')
plt.ylabel('Accuracy')
plt.title("Accuracy-Logistic Regression")

plt.savefig('Binary Classification: Logistic Regression Accuracy')

print (LRtrainAcc)
print (LRtestAcc)

# C = [0.01, 0.1, 0.2, 0.5, 0.8, 1, 5, 10, 20, 50] --> 0.2 is the best value for for C

plt.plot(C, LRtrainPrecision, 'ro-', C, LRtestPrecision,'bv--')
plt.legend(['Training Precision','Test Precision'])
plt.xlabel('C')
plt.xscale('Log')
plt.ylabel('Precision')
plt.title("Precision-Logistic Regression")
print (LRtrainPrecision)
print (LRtestPrecision)

plt.plot(C, LRtrainRecall, 'ro-', C, LRtestRecall,'bv--')
plt.legend(['Training Recall','Test Recall'])
plt.xlabel('C')
plt.xscale('Log')
plt.ylabel('Recall')
plt.title("Recall-Logistic Regression")
print (LRtrainRecall)
print (LRtestRecall)

plt.plot(C, LRtrainF1, 'ro-', C, LRtestF1,'bv--')
plt.legend(['Training F1 score','Test F1 score'])
plt.xlabel('C')
plt.xscale('Log')
plt.ylabel('F1 score')
plt.title("F1score-Logistic Regression")
print (LRtrainF1)
print (LRtestF1)

#SVM -metrics

plt.plot(C, SVMtrainAcc, 'ro-', C, SVMtestAcc,'bv--')
plt.legend(['Training Accuracy','Test Accuracy'])
plt.xlabel('C')
plt.xscale('Log')
plt.ylabel('Accuracy')
plt.title("SVM Linear - Accuracy")

plt.savefig('Binary Classification: Support Vector Machine')

print (SVMtrainAcc)
print(SVMtestAcc)

plt.plot(C, SVMtrainRecall, 'ro-', C, SVMtestRecall,'bv--')
plt.legend(['Training Recall','Test Recall'])
plt.xlabel('C')
plt.xscale('Log')
plt.ylabel('Recall')
plt.title("SVM Linear - Recall")
print (SVMtrainRecall)
print (SVMtestRecall)

plt.plot(C, SVMtrainPrecision, 'ro-', C, SVMtestPrecision,'bv--')
plt.legend(['Training Precision','Test Precision'])
plt.xlabel('C')
plt.xscale('Log')
plt.ylabel('Precision')
plt.title("SVM Linear - Precision")
print (SVMtrainPrecision)
print (SVMtestPrecision)

plt.plot(C, SVMtrainF1, 'ro-', C, SVMtestF1,'bv--')
plt.legend(['Training F1 score','Test F1 score'])
plt.xlabel('C')
plt.xscale('Log')
plt.ylabel('F1 score')
plt.title("SVM Linear - F1 score")
print (SVMtrainF1)
print (SVMtestF1)

#Algorithm - Non SVM

C = [0.01, 0.1, 0.2, 0.5, 0.8, 1, 5, 10, 20, 50]
SVMtrainAcc = []
SVMtestAcc = []
SVMtrainPrecision =[];
SVMtestPrecision = [];
SVMtrainRecall = [];
SVMtestRecall = [];
SVMtrainF1 = [];
SVMtestF1 = [];

for param in C:
    clf = SVC(C=param,kernel='rbf',gamma='auto')
    clf.fit(X_train_std, Y_train.values.ravel())
    Y_predTrain = clf.predict(X_train_std)
    Y_predTest = clf.predict(X_test_std)
    SVMtrainAcc.append(accuracy_score(Y_train, Y_predTrain))
    SVMtestAcc.append(accuracy_score(Y_test, Y_predTest))
    SVMtrainPrecision.append (precision_score(Y_train, Y_predTrain))
    SVMtestPrecision.append (precision_score(Y_test, Y_predTest))
    SVMtrainRecall.append (recall_score(Y_train, Y_predTrain))
    SVMtestRecall.append (recall_score(Y_test, Y_predTest))
    SVMtrainF1.append (f1_score(Y_train, Y_predTrain))
    SVMtestF1.append (f1_score(Y_test, Y_predTest))

fig, (ax2, ax3, ax4, ax5) = plt.subplots(4,1, figsize=(15,25))

ax2.plot(C, SVMtrainAcc, 'ro-', C, SVMtestAcc,'bv--')
ax2.legend(['Training Accuracy','Test Accuracy'])
ax2.set_xlabel('C')
ax2.set_xscale('log')
ax2.set_ylabel('SVM Accuracy')
ax2.title.set_text("Non Linear -SVM Accuracy")


ax3.plot(C, SVMtrainPrecision, 'ro-', C, SVMtestPrecision,'bv--')
ax3.legend(['Training Precision','Test Precision'])
ax3.set_xlabel('C')
ax3.set_xscale('log')
ax3.set_ylabel('Precision')
ax3.title.set_text("Non Linear- SVM Precision")

ax4.plot(C, SVMtrainRecall, 'ro-', C, SVMtestRecall,'bv--')
ax4.legend(['Training Recall','Test Recall'])
ax4.set_xlabel('C')
ax4.set_xscale('log')
ax4.set_ylabel('Recall')
ax4.title.set_text("Non Linear-SVM Recall")

ax5.plot(C, SVMtrainF1, 'ro-', C, SVMtestF1,'bv--')
ax5.legend(['Training F1','Test F1'])
ax5.set_xlabel('C')
ax5.set_xscale('log')
ax5.set_ylabel('F1 score')
ax5.title.set_text("Non Linear-SVM F1 score")

print (SVMtrainAcc)
print (SVMtestAcc)
print (SVMtrainPrecision)
print (SVMtestPrecision)
print (SVMtrainRecall)
print (SVMtestRecall)
print (SVMtrainF1)
print (SVMtestF1)

"""## Ensemble Learning for Binary Classification"""

from sklearn.ensemble import BaggingClassifier # for bagging 
from mlxtend.classifier import EnsembleVoteClassifier # for hard majority voting  

from mlxtend.plotting import plot_decision_regions
import matplotlib.gridspec as gridspec
import itertools


from sklearn.tree import DecisionTreeClassifier # to use at bagging 

from sklearn.linear_model import LogisticRegression

from sklearn.svm import SVC 

from sklearn import model_selection


from sklearn.decomposition import PCA 

from sklearn.metrics import accuracy_score, roc_curve, roc_auc_score

# check X_train shape 
X_train_std.shape

# check X_test shape 
X_test_std.shape

# check the unique values in Y_train 
np.unique(Y_train)

# chcek no of instances of each target values
unique, counts = np.unique(Y_train, return_counts=True)
dict(zip(unique, counts))

# check the unique values in Y_test
np.unique(Y_test)

Xr = X_resDataframe

X_resDataframe.head() # it is here

yr = Y_bc_resDataframe

Y_bc_resDataframe.tail()
yr.describe()

# split the resampled data set
from sklearn.model_selection import train_test_split

Xr_train, Xr_test, yr_train, yr_test = train_test_split(X_resDataframe, Y_resDataframe, test_size=0.2)

# 7.2 Majority Voting

# Ensemble Classifier

# We need multiple classifiers here. I choose
# 1. Logistic Regression
# 2. Decision Tree with Entropy
# 3. kNN with Euclidean Distance
# 4. non-linear SVM

clf1 = LogisticRegression(C=0.2) # C = 0.2
clf2 = SVC(C=1.0)  # linear SVM C = 1
clf3 = KNeighborsClassifier(n_neighbors=best_k) # pass best_k=7
clf4 = DecisionTreeClassifier(criterion='entropy')


labels = ['Logistic Regression', 'Support Vector Machine', 'K Nearest Neighbor', 'Decision Tree', 'Ensemble']
#eclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3, clf4], weights= [1, 1, 1, 1] )  # works

eclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3, clf4], weights=[1,1,1, 1])


for clf, label in zip([clf1, clf2, clf3, clf4, eclf], labels):
 
  #clf.fit(Xr_train_std, yr_train)
 
  # pass the complete data set
  scores = model_selection.cross_val_score(clf, Xr, yr, # we have used  complete dataset
                                              cv=10, # returned better accuracy
                                              scoring='accuracy')
  print("Accuracy: %0.2f (+/- %0.2f) [%s]" % (scores.mean(), scores.std(), label))


#print(best_k)

#Accuracy: 0.99 (+/- 0.02) [Logistic Regression]
#Accuracy: 0.99 (+/- 0.02) [Support Vector Machine]
#Accuracy: 0.99 (+/- 0.02) [K Nearest Neighbor]
#Accuracy: 0.97 (+/- 0.07) [Decision Tree]
#Accuracy: 0.99 (+/- 0.03) [Ensemble]




# X, y -> X_resDataFrame_std, yr

# Plot the decision region



gs = gridspec.GridSpec(2, 2)

fig = plt.figure(figsize=(10,8))

labels = ['Logistic Regression', 'Support Vector Machine', 'K Nearest Neighbor', 'Decision Tree', 'Ensemble']


# convert X_resDataFrame_std to numpy
Xr = pd.DataFrame(Xr).to_numpy()
Xr_np = Xr.astype(np.float)

pca = PCA(n_components=2)

Xr_np = pca.fit_transform(Xr_np)

yr_np = pd.DataFrame(yr).to_numpy()
yr_np = yr_np.astype(np.int).flatten()

for clf, lab, grd in zip([clf1, clf2, clf3, clf4, eclf], labels, itertools.product([0, 1], repeat=2)):
    clf.fit(Xr_np, yr)
   
    ax = plt.subplot(gs[grd[0], grd[1]])
    fig = plot_decision_regions(X=Xr_np, y=yr_np, clf=clf)
   
    plt.savefig('Decision Boundaries For Binary Classification')
    plt.title(lab)

clf1 = LogisticRegression(C=0.2) # C = 0.2
clf2 = SVC(C=1.0)  # linear SVM C = 1
clf3 = KNeighborsClassifier(n_neighbors=best_k) # pass best_k=7
clf4 = DecisionTreeClassifier(criterion='entropy')



eclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3, clf4], weights=[1,1,1, 1])


for clf, label in zip([clf1, clf2, clf3, clf4, eclf], labels):
   
  clf.fit(X, y)
 
  scores = model_selection.cross_val_score(clf, X, y, 
                                              cv=10, # returned better accuracy
                                              scoring='accuracy')
  print("Accuracy for original dataset: %0.2f (+/- %0.2f) [%s]" % (scores.mean(), scores.std(), label))



# 7.3 Bagging 
# Bagging Classifier 

# We use unpruned Decision Tree as our classifer in Bagging 

tree = DecisionTreeClassifier(criterion='entropy', 
                              random_state=1, 
                              max_depth=None) # We keep max_depth=None to have unpruned Decision Tree

# The number of trees can be set via the “n_estimators” argument 
bag = BaggingClassifier(base_estimator=tree, 
                        n_estimators= 10, 
                        bootstrap=True, 
                        bootstrap_features=False,                          
                        random_state=1,
                        oob_score=True
                        )


bag.fit(X_train_std, Y_train)

print('Out Of Bag Score: ', bag.oob_score_)
print('Test Accuracy Score: ', bag.score(X_test_std, Y_test), '\n\n\n' )

# Random Forest 

# Xr_train, Xr_test, yr_train, yr_test

from sklearn.ensemble import RandomForestClassifier 

forest = RandomForestClassifier(criterion='gini', n_estimators=100, random_state=1)


# convert X_resDataFrame_std to numpy
Xr_train_np = pd.DataFrame(Xr_train).to_numpy()
Xr_train_np = Xr_train_np.astype(np.float)

pca = PCA(n_components=2)

Xr_train_np = pca.fit_transform(Xr_train_np)

forest.fit(Xr_train_np, yr_train) # pass training set


yr_train_np = pd.DataFrame(yr_train).to_numpy()
yr_train_np = yr_train_np.astype(np.int).flatten()



# Plotting decision regions
plot_decision_regions(Xr_train_np, yr_train_np, clf=forest, legend=2)

# Adding axes annotations
plt.xlabel('')
plt.ylabel('')
plt.title('')
plt.savefig('Binary Classification: Random Forest Decision Boundary')
plt.show()

# Now test the accuracy
predictions = forest.predict(pca.transform(Xr_test))

acc =  accuracy_score(predictions,yr_test)

print('Random Forest Accuracy: ', acc)

from sklearn.metrics import accuracy_score, roc_curve, roc_auc_score

# ROC Curve


# Work on ROC Curve from here 

  # 1. Logistic Regression : clf1 
  # 2. SVM : clf2
  # 3. kNN with Euclidean Distance
  # 4. Decision Tree with Entropy

clf1 = LogisticRegression(C=0.2) # C = 0.2 - Check with SR- If time permits.
clf2 = SVC(C=10, probability=True)  # linear SVM C = 10 
clf3 = KNeighborsClassifier(n_neighbors=best_k) # pass best_k=7
clf4 = DecisionTreeClassifier( criterion='entropy') # - Check with SR


from sklearn.model_selection import train_test_split
Xr_train, Xr_test, yr_train, yr_test = train_test_split(X_resDataframe, Y_resDataframe, test_size=0.2)


# Standarise the data for convenience 
sc = StandardScaler

#sc.fit(Xr_train)
#Xr_train_std = sc.transform(X_train)
#Xr_test_std = sc.transform(Xr_test)

# Fit trainig data on models 
clf1.fit(Xr_train, yr_train)
clf2.fit(Xr_train, yr_train)
clf3.fit(Xr_train, yr_train)
clf4.fit(Xr_train, yr_train)

# make predictions
clf1_predictions = clf1.predict(Xr_test)
clf2_predictions = clf2.predict(Xr_test)
clf3_predictions = clf3.predict(Xr_test)
clf4_predictions = clf4.predict(Xr_test)

# view accuracy scores 
acc1  = accuracy_score(clf1_predictions, yr_test)
acc2  = accuracy_score(clf2_predictions, yr_test)
acc3  = accuracy_score(clf3_predictions, yr_test)
acc4  = accuracy_score(clf4_predictions, yr_test)

print('Accuracy for: ')
print('\tLog Reg: ', acc1)
print('\tSVM: ', acc2)
print('\t kNN: ', acc3)
print('\tDecision Tree: ', acc4)
print("\n\n\n")

# get probability scores 

# probas = lr.fit(X_train_std, y_train).predict_proba(X_test_std) # return the probability for each class : first row->0, second row->1

proba1 = clf1.fit(Xr_train, yr_train).predict_proba(Xr_test)
proba2 = clf2.fit(Xr_train, yr_train).predict_proba(Xr_test) 
proba3 = clf3.fit(Xr_train, yr_train).predict_proba(Xr_test)
proba4 = clf4.fit(Xr_train, yr_train).predict_proba(Xr_test)


#proba1[:, 1].shape (216, )
#yr_test.shape # (216, 1)

#pd.DataFrame({"A": [1, 2], "B": [3, 4]}).to_numpy()

yr_test = pd.DataFrame( yr_test ).to_numpy()

yr_test = yr_test.reshape(216)

yr_test.shape # I have yr_test in the shape we want 

proba1[:,1].shape


fpr1, tpr1 , thresholds1 = roc_curve( yr_test, proba1[:, 1], pos_label=1)
fpr2, tpr2 , thresholds2 = roc_curve( yr_test, proba2[:, 1], pos_label=1)
fpr3, tpr3 , thresholds1 = roc_curve( yr_test, proba3[:, 1], pos_label=1)
fpr4, tpr4 , thresholds1 = roc_curve( yr_test, proba4[:, 1], pos_label=1)



#print('tpr1 : ', tpr1)
#print('fpr1 : ', fpr1)
#print('thresholds1 : ', thresholds1) # works 


# auc score

auc_score1 = roc_auc_score(yr_test, proba1[:,1])
print('roc_auc_score: ', auc_score1)

auc_score2 = roc_auc_score(yr_test, proba2[:,1])
print('roc_auc_score: ', auc_score1)

auc_score3 = roc_auc_score(yr_test, proba3[:,1])
print('roc_auc_score3: ', auc_score3)

auc_score4 = roc_auc_score(yr_test, proba4[:,1])
print('roc_auc_score4: ', auc_score4)


# 1. Logistic Regression : clf1 
  # 2. SVM : clf2
  # 3. kNN with Euclidean Distance
  # 4. Decision Tree with Entropy



# plot roc curves

plt.plot(fpr1, tpr1, color='b', label='Logistic Regression')
plt.plot(fpr2, tpr2, color='g', label='SVM')
plt.plot(fpr3, tpr3, color='c', label='kNN')
plt.plot(fpr4, tpr4, color='m', label='Decision Tree')



plt.plot([0,1], [0,1], linestyle=':', color='red', label='Random Guessing')

plt.title('ROC Title')
plt.legend(loc='best')

plt.savefig('ROC Curve for Logistic Regression', 'kNN', 'Decision Tree')

plt.show()

a  = np.arange(3)        # a.shape  = (3,)
b  = a.reshape((3,1))    # b.shape  = (3,1)
b2 = a.reshape((-1,1))   # b2.shape = (3,1)
c  = b.reshape((3,))     # c.shape  = (3,)
c2 = b.reshape((-1,))    # c2.shape = (3,)


print(b2.shape)
print( c.shape ) 
print( c2.shape )

"""# Multi-class classification"""

#Multiclass classification - Starts here.
df_multiclass.head(5)

df_multiclass.groupby('Category').nunique()

#Displaying the dataframe.
# df_multiclass['Category']= category
print (df_multiclass.head(5))

"""Converting the columns sex values"""

#Converting the sex column male and female to 1's and 0's
df_multiclass.loc[(df_multiclass.Sex == 'm'), 'Sex'] = 1
df_multiclass.loc[(df_multiclass.Sex == 'f'), 'Sex'] = 0
df_multiclass.head(5)

df_multiclass.groupby('Category').nunique()

Y_multiclass= pd.DataFrame(data= df_multiclass['Category']);
X_multiclass= df_multiclass.drop(['Category'], axis=1);

X_multiclass_colnames = X_multiclass.columns;

# SR: check if all the target values are present 

df_multiclass['Category'].unique()

"""**Data oversampling to address the class imbalance problem**"""

# oversampling the data 

from imblearn.over_sampling import SMOTE


sm = SMOTE(random_state=42)
X_res_multiclass, Y_res_multiclass = sm.fit_resample(X_multiclass, Y_multiclass)
# type(Y)

# print (type(X_res))

X_res_multiclass.shape # (615, 13) 51
Y_res_multiclass.shape # (1080, 13)

X_resDataframe1 = pd.DataFrame(data=X_res_multiclass, columns=X_multiclass_colnames);
Y_resDataframe1 =  pd.DataFrame(data=Y_res_multiclass, columns=["Category"]);

"""**Resampled data- Check**"""

X_resDataframe1.shape

Y_res_multiclass.shape

X_resDataframe1= X_resDataframe1.drop(["Unnamed: 0"], axis=1);
X_resDataframe1.head(5)

Y_resDataframe1.head(5)

"""**Standardize the X_resDataframe1 dataset**



"""

from sklearn.preprocessing import StandardScaler

sc = StandardScaler()
X_resDataframe1_transform= sc.fit_transform(X_resDataframe1)
X_resDataframe1_df = pd.DataFrame(data=X_resDataframe1_transform, columns=X_multiclass_colnames[1:]);

"""**Checking whether the features are standardized or not**"""

X_resDataframe1_df.head(5)

"""**Checking the unique and frequency values in Y_resDataframe**"""

unique, frequency = np.unique(Y_resDataframe1,  
                              return_counts = True) 
# print unique values array 
print("Unique Values:",  
      unique) 
  
# print frequency array 
print("Frequency Values:", 
      frequency)

"""**Splitting the dataset into xtrain, ytrain, xtest and ytest**"""

#Train and test dataset for multi-label classification
X_train, X_test, Y_train, Y_test = train_test_split(X_resDataframe1_df,Y_resDataframe1,train_size=0.8, test_size=0.2, random_state=1)

"""**Decision tree for Multi-class classification starts here**"""

# SR: Alright: Goes into report 

#Classification algorithm - Decision tree
maxdepths = [*range(1,50,1)];

#To keep track of the k scores.
scores = [];
plotScores = [];

trainAcc = np.zeros(len(maxdepths))
testAcc = np.zeros(len(maxdepths))


index = 0
for depth in maxdepths:
    clf = tree.DecisionTreeClassifier(max_depth=depth, criterion="entropy")
    clf = clf.fit(X_train_std, Y_train)
    Y_predTrain = clf.predict(X_train_std)
    Y_predTest = clf.predict(X_test_std)
    trainAcc[index] = accuracy_score(Y_train, Y_predTrain)
    testAcc[index] = accuracy_score(Y_test, Y_predTest)
    scores.append([depth, accuracy_score(Y_test, Y_predTest)])
    plotScores.append(accuracy_score(Y_test, Y_predTest));  
    index+=1;
        
plt.plot(maxdepths,trainAcc,'ro-',maxdepths,testAcc,'bv--')
plt.legend(['Training Accuracy','Test Accuracy'])
plt.xlabel('Max depth')
plt.ylabel('Accuracy')
plt.title("Decision Tree-Accuracy")
print ('Mean Trainaccuracy: %0.5f'%mean(trainAcc));
print ('Mean Testaccuracy: %0.5f' %mean(testAcc));

#printing the test accuracy scores.
for i in scores:
  print ("The maxDepth value is %d and the accuracy score is %0.5f" % (i[0], i[1]));

#Finding and printing the optimum Depth value for Decision tree
finalResult = [];
maxAccuracy = max(plotScores);

for i in scores:
  if (i[1]== maxAccuracy):
   optimum_Depth = i[0]  #optimumDepth value
   finalResult.append([i[0], i[1]]);

for i in finalResult:
 print ("The optimum maxdepth value is %d and the max test accuracy score is %0.5f" % (i[0],i[1]));

"""**KNN classifier for Multi-class classification starts here**"""

#KNN classifier.
i_ = []
mu = []
for i in range(1, 101): 
    
    knn = KNeighborsClassifier(n_neighbors=i)
    #cross_val_score( X, y) # parameters: estimator, X, target label, n_splits 
    scores = cross_val_score(knn, X_resDataframe1_df, Y_resDataframe1.values.ravel(), cv=10, scoring='accuracy') 
    
    #print(scores)
    #print('Scores for i= ', i, ': ', scores.mean())
    i_.append( i ) # k value 
    mu.append( scores.mean() ) # accuracy

print()

# plot test and training accuracy onto one graph 

plt.plot(i_, mu, label='Accuracy vs K value')

plt.xlabel('K value')
plt.ylabel('Accuracy/%')

plt.legend(loc='upper right')
plt.grid(alpha=0.5)

plt.savefig('Best K Value: k_fold_cross_validation_acc_vs_kvalue.png') # We need this 

plt.show()



# Find the k value for maximum accuracy 
max(mu) # 98 %
max_ = []
# find the indices for max
for i in range( len(mu) ):
    if mu[i] == max(mu):
        max_.append(i+1)

best_k_mc = max_[0]        
print ("The max accuracy for the original dataset %0.6f" %max(mu))
print('Optimum k value for the original dataset', max_ )

"""**SVM linear algorithm for Multi-class classification starts here**"""

#Algorithm - SVM-linear

C = [0.01, 0.1, 0.2, 0.5, 0.8, 1, 5, 10, 20, 50]
SVMtrainAcc = []
SVMtestAcc = []

#To keep track of the test accuracy scores.
scores = [];
plotScores = [];

for param in C:
    clf = SVC(C=param, kernel='linear')
    clf.fit(X_train_std, Y_train.values.ravel())
    Y_predTrain = clf.predict(X_train_std)
    Y_predTest = clf.predict(X_test_std)
    SVMtrainAcc.append(accuracy_score(Y_train, Y_predTrain))
    SVMtestAcc.append(accuracy_score(Y_test, Y_predTest))
    scores.append([param, accuracy_score(Y_test, Y_predTest)])
    plotScores.append(accuracy_score(Y_test, Y_predTest));

#SVM -metrics
plt.plot(C, SVMtrainAcc, 'ro-', C, SVMtestAcc,'bv--')
plt.legend(['Training Accuracy','Test Accuracy'])
plt.xlabel('C')
plt.xscale('Log')
plt.ylabel('Accuracy')
plt.title("SVM Linear - Accuracy")
print ('Trainaccuracy: %0.5f'%mean(SVMtrainAcc));
print ('Testaccuracy: %0.5f' %mean(SVMtestAcc));

#printing the test accuracy scores.
for i in scores:
  print ("The param value is %f and the accuracy score is %0.5f" % (i[0], i[1]));

#Finding and printing the optimum param value for SVM linear model - The optimal parameter value is 10.
finalResult = [];
maxAccuracy = max(plotScores);

for i in scores:
  if (i[1]== maxAccuracy):
   optimum_param = i[1]  #optimumParam value
   finalResult.append([i[0], i[1]]);

for i in finalResult:
 print ("The optimum parameter value is %f and the max test accuracy score is %0.5f" % (i[0],i[1]));

"""**Logistic Regression for Multi-class classification starts here**

---


"""

#Algorithm - Logistic regression

from sklearn import linear_model
from sklearn.svm import SVC

C = [0.01, 0.1, 0.2, 0.5, 0.8, 1, 5, 10, 20, 50]
LRtrainAcc = []
LRtestAcc = []

#To keep track of the test accuracy scores.
scores = [];
plotScores = [];


for param in C:
    clf = linear_model.LogisticRegression(C=param)
    clf.fit(X_train_std, Y_train.values.ravel())
    Y_predTrain = clf.predict(X_train_std)
    Y_predTest = clf.predict(X_test_std)
    LRtrainAcc.append(accuracy_score(Y_train, Y_predTrain))
    LRtestAcc.append(accuracy_score(Y_test, Y_predTest))
    scores.append([param, accuracy_score(Y_test, Y_predTest)])
    plotScores.append(accuracy_score(Y_test, Y_predTest));

#Logistic regression -metrics
plt.plot(C, LRtrainAcc, 'ro-', C, LRtestAcc,'bv--')
plt.legend(['Training Accuracy','Test Accuracy'])
plt.xlabel('C')
plt.xscale('Log')
plt.ylabel('Accuracy')
plt.title("Logistic Regression - Accuracy")
print ('Mean Trainaccuracy: %0.5f'%mean(SVMtrainAcc));
print ('Mean Testaccuracy: %0.5f' %mean(SVMtestAcc));

#printing the test accuracy scores.
for i in scores:
  print ("The param value is %f and the accuracy score is %0.5f" % (i[0], i[1]));

#Finding and printing the optimum param value for Logistic regression model
finalResult = [];
maxAccuracy = max(plotScores);

for i in scores:
  if (i[1]== maxAccuracy):
   optimum_param_LR = i[1]  #optimumParam value
   finalResult.append([i[0], i[1]]);

for i in finalResult:
 print ("The optimum param value is %f and the max test accuracy score is %0.5f" % (i[0],i[1]));

"""**Ensemble learning for Multi-class classification**"""

# 7.2 Majority Voting 

# Ensemble Classifier

# We need multiple classifiers here. I choose
# 1. Logistic Regression
# 2. Decision Tree with Entropy
# 3. kNN with Euclidean Distance 
# 4. non-linear SVM 

clf1 = LogisticRegression(C=optimum_param_LR) # C = 0.2 - Check with SR- If time permits.
clf2 = SVC(C=10)  # linear SVM C = 10 
clf3 = KNeighborsClassifier(n_neighbors=best_k) # pass best_k=7
clf4 = DecisionTreeClassifier(max_depth= optimum_Depth, criterion='entropy') # - Check with SR


labels = ['Logistic Regression', 'Support Vector Machine', 'K Nearest Neighbor', 'Decision Tree']
eclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3, clf4], weights= [1, 1, 1, 1] )  # works


for clf, label in zip([clf1, clf2, clf3, clf4], labels): 
  
  clf.fit(X_resDataframe, Y_resDataframe)
 
  scores = model_selection.cross_val_score(clf, X_resDataframe1_df, Y_resDataframe1.values.ravel(), 
                                              cv=20, # returned better accuracy
                                              scoring='accuracy')
  print("Accuracy: %0.2f (+/- %0.2f) [%s]" % (scores.mean(), scores.std(), label))

#SVM - non linear algorithm


#visualize_all(SVC(kernel='rbf',gamma='auto'),X_train_std,Y_train,X_test_std,Y_test,Y_resDataframe)